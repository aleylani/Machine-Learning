{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Assignment\n",
    "\n",
    "For this lab, we're going to use everything we've learned so far and try to predict bike demand using linear models!\n",
    "\n",
    "The data comes from this [page](https://www.kaggle.com/datasets/lakshmi25npathi/bike-sharing-dataset)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "    1. Download the dataset. \n",
    "    \n",
    "In fact, by doing so you'll get two datasets. One is *daily* bike demand, and the other is *hourly* bike demand.\n",
    "The daily dataset has fewer records (731) and might be a bit simpler to work with if you're just getting started.\n",
    "If you want to have a bit more fun, go for the hourly dataset (17379 records).\n",
    "\n",
    "Pick the one you want! \n",
    "\n",
    "    2. Read carefully through the documentation for the dataset. \n",
    "\n",
    "The download will also include a *readme* with good information about the dataset and descriptions for all the columns in it. The target we're going to try to model is the column *cnt*. \n",
    "\n",
    "You are forbidden to use the columns *casual* and *registered*. Why do you think that is?\n",
    "\n",
    "    3. Conduct some initial EDA.\n",
    "\n",
    "Get to know the data by e.g. doing some initial plots and some statistics in order to try to understand what you're dealing with. \n",
    "\n",
    "While doing this, also think carefully about what features you'd think are relevant to what we're trying to predict. \n",
    "\n",
    "Which feature(s) do you have reasons to believe might be the individually most reliable one(s) to predict the demand?\n",
    "\n",
    "    4. Clean data\n",
    "\n",
    "If warranted, start cleaning data.\n",
    "\n",
    "    5. Model\n",
    "\n",
    "Pick the features you think or have reasons to believe are relevant. Then, train a linear model and evaluate it. Does it perform well?\n",
    "\n",
    "In this step, you are of course allowed to train many different models wherein you have different features for all of them. \n",
    "\n",
    "Can you find a particular combination of features that seem to work best?\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**ALI KLADDAR NEDAN**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('../data/bike_rental/day.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.drop(columns=['casual', 'registered', 'dteday', 'instant'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X, y = df.drop(columns=['cnt']).values, df['cnt'].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=40)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.metrics import mean_squared_error\n",
    "\n",
    "rf = RandomForestRegressor(max_depth=12, random_state=0)\n",
    "rf.fit(X, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train_hat = rf.predict(X_train)\n",
    "y_test_hat = rf.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Train:')\n",
    "print(f'RMSE: {mean_squared_error(y_train, y_train_hat)**0.5}')\n",
    "\n",
    "print('Test:')\n",
    "print(f'RMSE: {mean_squared_error(y_test, y_test_hat)**0.5}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "machinelearning",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
