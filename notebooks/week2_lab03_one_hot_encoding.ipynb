{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Problem statement\n",
    "\n",
    "For many ML-models, but not all, it is required that all the input features are numerical - since the values they have are being used in mathematical operations. \n",
    "However, in the previous lab with the used cars dataset, we had to omit all features that were not already numerical since we hadn't yet learned how to deal with them.\n",
    "\n",
    "In this lab, we'll learn of a technique called One Hot Encoding, which is a method of transforming what we call *categorical* features into numerical ones."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Let's randomly generate a dataset to work with here**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ages = np.random.randint(20, 60, size=10)\n",
    "genders = np.random.choice(['male', 'female', 'other'], size=10)\n",
    "salaries = np.random.randint(30000, 80000, size=10)\n",
    "\n",
    "data = {'Age': ages, 'Gender': genders, 'Salary': salaries}\n",
    "df = pd.DataFrame(data)\n",
    "\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In the dataset above, the column Gender is called *categorical*.\n",
    "\n",
    "A categorical feature is one in which we can't say that one value is more or less than another one. \n",
    "\n",
    "In this case, male is neither more or less than female, i.e., we can't say that male < female or vice-versa.\n",
    "\n",
    "Some other examples of categorical data are hair color (red, blonde, or black), political affiliation (republican, democrat, or other), and favourite food (sushi, kebab, or vegetables). Again, these are considered categorical because one is not more than the other.\n",
    "\n",
    "In contrast, the columns Age and Salary are definitely not categorical since you can directly compare them. A salary of 60000 > 30000, and conversely 39 is objectively older than 26."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**One Hot Encoding**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A very simple way of dealing with categorical features is simply to create boolean columns, one for each of the values of our categorical column. This is called one hot encoding. We can do this in several ways, and Pandas has a pretty neat function for it aswell."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1. we call on the get_dummies function\n",
    "# 2. we give it the dataset as the first argument\n",
    "# 3. We tell it which columns we want to one hot encode\n",
    "\n",
    "pd.get_dummies(df, columns = ['Gender']) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1. we call on the get_dummies function\n",
    "# 2. we give it the dataset as the first argument\n",
    "# 3. We tell it which columns we want to one hot encode\n",
    "# 4. In addition, we also let the function know that we want 1/0 and not True/False\n",
    "\n",
    "pd.get_dummies(df, columns = ['Gender'], dtype=int)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The result is a new dataframe, with categorical features transformed into numerical ones that we can use for the models that require it! \n",
    "\n",
    "If now use these features to try to predict the salary for a given employee, we might have something like this (for a linear model)\n",
    "\n",
    "$$ salary = w_3 \\cdot (Age) + w_2 \\cdot (Gender\\ female) + w_1 \\cdot (Gender\\ male) + w_0 $$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**A word of caution**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "However, you must be careful to not fall into the trap of believing that numerical columns can't be categorical! \n",
    "\n",
    "Take this for example:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ages = np.random.randint(20, 60, size=10)\n",
    "genders = np.random.choice(['male', 'female'], size=10)\n",
    "employee_ids = np.random.randint(200, 600, size=10)\n",
    "salaries = np.random.randint(30000, 80000, size=10)\n",
    "\n",
    "data = {'Employee ID': employee_ids, 'Age': ages, 'Gender': genders, 'Salary': salaries}\n",
    "df = pd.DataFrame(data)\n",
    "\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Obviously, Employee ID is a numerical column and we can technically do mathematical comparisons between each Employee ID.\n",
    "\n",
    "532 > 220. Obviously.\n",
    "\n",
    "However, imagine using column, as is, as a feature for, say, a linear model that predicts salary. Then it might look like this:\n",
    "\n",
    "$$ salary = w_2 \\cdot (Employee\\ ID) + w_1 \\cdot (Age) + w_0 $$\n",
    "\n",
    "According to this, a higher Employee ID contributes more to the predicted salary than a lower Employee ID. That doesn't seem to make any sense at all.\n",
    "\n",
    "In fact, the column Employee ID is also a categorical feature, a *numerical categorical* feature. We could technically do comparisons between its values, but we really shouldn't - since it doesnt make sense. \n",
    "\n",
    "We can treat numerical categorical columns just like we did with ordinary categorical features - we'll one hot encode them.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.get_dummies(df, columns = ['Gender', 'Employee ID'], dtype=int)  # note that we can one hot encode several columns at the same time"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "För mer information, läs [dokumentationen!](https://pandas.pydata.org/docs/reference/api/pandas.get_dummies.html)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ages = np.random.randint(20, 60, size=10)\n",
    "genders = np.random.choice(['male', 'female', 'other'], size=10)\n",
    "education = np.random.choice(['high school', 'bachelor', 'phd'], size=10)\n",
    "salaries = np.random.randint(30000, 80000, size=10)\n",
    "\n",
    "data = {'Age': ages, 'Gender': genders, 'Education': education, 'Salary': salaries}\n",
    "df = pd.DataFrame(data)\n",
    "\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def edu_mapper(value):\n",
    "\n",
    "    if value=='phd':\n",
    "        return 3\n",
    "    elif value=='bachelor': \n",
    "        return 2\n",
    "    else:\n",
    "        return 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "numerical_education = [edu_mapper(level) for level in df['Education']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['New Education'] = numerical_education"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$$ salary = w_2 \\cdot (Age) + w_1 \\cdot (New\\ Education) + w_0$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ni kan göra som ovan, men ni kan också givetvis köra dummy variables ändå. Trots att Education inte är kategorisk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ages = np.random.randint(20, 60, size=10)\n",
    "genders = np.random.choice(['male', 'female', 'other'], size=10)\n",
    "education = np.random.choice(['high school', 'bachelor', 'phd'], size=10)\n",
    "salaries = np.random.randint(30000, 80000, size=10)\n",
    "\n",
    "data = {'Age': ages, 'Gender': genders, 'Education': education, 'Salary': salaries}\n",
    "df = pd.DataFrame(data)\n",
    "\n",
    "\n",
    "pd.get_dummies(df, columns = ['Education'], dtype=int)  # note that we can one hot encode several columns at the same time"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$$ salary = w_4 \\cdot (Age) + w_3 \\cdot (Education\\ bachelor) + w_2 \\cdot (Education\\ high\\ school) + w_1 \\cdot (Education\\ phd) + w_0$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**The curse of dimensionality**\n",
    "\n",
    "One Hot Encoding is great, but you should be careful using it. If the categorical column you transform has too many values, it will translate to equally many new columns. This means that the dimensionality of your features increases (each feature is one dimension). As you increase the number of features, it also turns out that it gets more and more difficult to fit a model to it - unless you have a big enough data set!\n",
    "\n",
    "Think about it. If you have a very small data set (10 samples), and 1000 features - you're not going to be able to make any sense of the underlying process you're trying to model.\n",
    "\n",
    "However, if you have a relatively big data set (1M samples), and 1000 features - you might be able to make sense of the underlying process and produce a good model.\n",
    "\n",
    "**conclusion**\n",
    "\n",
    "One Hot Encoding is great, use it. But be careful. If the column your transforming has *alot* of possible values (say, perhaps over 20 or 30), it might case issues if you don't also have a correspondingly good amount of data.\n",
    "\n",
    "Clear warning sign: if the number of features exceed the number of training samples, you're most likely in trouble.\n",
    "\n",
    "What you want is for your training samples >> number of features"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "machinelearning",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
